<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Recipes on</title><link>https://kubedl.io/docs/recipes/</link><description>Recent content in Recipes on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 16 Mar 2021 08:43:03 +0100</lastBuildDate><atom:link href="https://kubedl.io/docs/recipes/index.xml" rel="self" type="application/rss+xml"/><item><title>File Sync</title><link>https://kubedl.io/docs/recipes/code-sync/</link><pubDate>Mon, 29 Mar 2021 23:04:09 -0700</pubDate><guid>https://kubedl.io/docs/recipes/code-sync/</guid><description>KubeDL supports syncing files from remote on container launch. User can modify the code, reference the code repository and run the jobs without re-building the image every time to include the modified code.
Currently, only support downloading from github. The implementation is pluggable and can easily support other distributed filesystem like HDFS.
Git Hub Users can set the git config in the job&amp;rsquo;s annotation with key kubedl.io/git-sync-config as below. The git repo will be downloaded and saved in the container&amp;rsquo;s working dir by default.</description></item><item><title>Host Network</title><link>https://kubedl.io/docs/recipes/hostnetwork/</link><pubDate>Fri, 02 Apr 2021 19:32:11 -0700</pubDate><guid>https://kubedl.io/docs/recipes/hostnetwork/</guid><description>Background Network bandwidth is a bottleneck resource for communication-intensive jobs. Host mode networking can be useful to optimize performance. In addition, other scenarios (e.g: nvlink communications between containerized gpu processes) may depend on host-network as well.
How To Use KubeDL provides a feature-gate to enable hostnetwork mode for jobs. Users only need to add an annotation kubedl.io/network-mode: host to the job specifications, for example:
apiVersion: &amp;quot;training.kubedl.io/v1alpha1&amp;quot; kind: &amp;quot;TFJob&amp;quot; metadata: name: &amp;quot;mnist&amp;quot; namespace: kubedl annotations: + kubedl.</description></item><item><title>Tensorboard</title><link>https://kubedl.io/docs/recipes/tensorboard/</link><pubDate>Wed, 07 Apr 2021 15:35:16 -0700</pubDate><guid>https://kubedl.io/docs/recipes/tensorboard/</guid><description>KubeDL can attach a tensorboard to a running tensorflow job. Users can visualize the tensorflow job with the tensorboard.
To use tensorboard, users must ensure that the tensorflow job logs are created and stored in a kubernetes remote volume (emptyDir, hostPath and local volume are not supported) and the tensorboard pod can mount the volume.
Users can set the tensorboard config in the job&amp;rsquo;s annotation with key kubedl.io/tensorboard-config as below. After that, users can access the tensorboard through this URL http://&amp;lt;ingress host&amp;gt;/&amp;lt;ingress pathPrefix&amp;gt;/&amp;lt;job namespace&amp;gt;/&amp;lt;job name&amp;gt;.</description></item><item><title>Metadata Persistency</title><link>https://kubedl.io/docs/recipes/metadata-persistency/</link><pubDate>Thu, 08 Apr 2021 14:47:51 -0700</pubDate><guid>https://kubedl.io/docs/recipes/metadata-persistency/</guid><description>Kubernetes api-server typically stores job information for a limited lifespan. KubeDL has built-in support to persist the job metadata into external storage to outlive api-server state. The KubeDL controller will persist the job metadata during the lifecycle of job such as job and pod creation/deletion.
Currently, only Mysql is supported.
DB Schema Job Table Column Type Description id int(64) primary id auto incremented by underlying database name varchar(128) name of job namespace varchar(128) namespace of job job_id varchar(64) job uid generated by kubernetes version varchar(32) resource version generated by kubernetes(etcd) status varchar(32) current observed job status(Created/Running/Failed/Succeed/Restarting) kind varchar(32) kind of job: TFJob,PyTorchJob&amp;hellip; resources text job requested resources, including replicas and resources of each role.</description></item><item><title>Events Persistency</title><link>https://kubedl.io/docs/recipes/events-persistency/</link><pubDate>Thu, 08 Apr 2021 14:48:07 -0700</pubDate><guid>https://kubedl.io/docs/recipes/events-persistency/</guid><description>Kubernetes object events are persisted for only 3 hours by default. In addition to job meta persistency, KubeDL also supports persisting Kubernetes events into external storage system (usually time-series databases) to outlive api-server state. Currently, KubeDL watches all Kubernetes events and persist them into external storage.
Currently, only aliyun-sls is supported.
How To Use Below is an example for seting up KubeDL to persist events into alicloud simple log service.</description></item><item><title>Dashboard</title><link>https://kubedl.io/docs/recipes/dashboard/</link><pubDate>Wed, 07 Apr 2021 15:35:16 -0700</pubDate><guid>https://kubedl.io/docs/recipes/dashboard/</guid><description>KubeDL Dashboard KubeDL dashboard consists of a frontend and a backend. Below documentation describes how to build and run them.
Prerequisites NodeJS &amp;gt; 10 Go &amp;gt; 1.12 Deployment Guide Deploy the KubeDL Dashboard kubectl apply -f console/dashboard.yaml This will create a kubedl-dashboard Deployment, its Service, and a ConfigMap in the kubedl-system namespace.
The dashboard will list nodes. Hence, its service account requires the list node permission.</description></item><item><title>Gang Scheduling</title><link>https://kubedl.io/docs/recipes/scheduling/</link><pubDate>Wed, 07 Apr 2021 15:35:16 -0700</pubDate><guid>https://kubedl.io/docs/recipes/scheduling/</guid><description>Gang Scheduling is a critical feature for Deep Learning workloads to enable all-or-nothing scheduling capability, as most DL frameworks requires all workers to be running to start training process. Gang Scheduling avoids resource inefficiency and scheduling deadlock sometimes.
KubeDL supports gang scheduling with different schedulers as a backend. Today, several Kubernetes schedulers support gang scheduling, including the Coscheduling Scheduling Plugin, YuniKorn, KubeBatch. Each has its own advantages and its own API protocols.</description></item></channel></rss>